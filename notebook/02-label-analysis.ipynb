{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Analysis - Legal Text Decoder\n",
    "\n",
    "This notebook analyzes the label distribution, class imbalance, and potential patterns in the annotations.\n",
    "\n",
    "Key questions:\n",
    "- How imbalanced are the classes?\n",
    "- Are there annotator biases across different data sources?\n",
    "- What class weights should we use for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open('../data/processed/all_data.json', 'r', encoding='utf-8') as f:\n",
    "    all_data = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "df['text_length'] = df['text'].str.len()\n",
    "\n",
    "# Label names\n",
    "label_names = {\n",
    "    1: 'Very Hard',\n",
    "    2: 'Hard',\n",
    "    3: 'Moderate',\n",
    "    4: 'Easy',\n",
    "    5: 'Very Easy'\n",
    "}\n",
    "\n",
    "print(f\"Total samples: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Class Imbalance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class imbalance metrics\n",
    "label_counts = df['label'].value_counts().sort_index()\n",
    "total = len(df)\n",
    "\n",
    "print(\"Class Distribution:\")\n",
    "print(\"=\"*50)\n",
    "for label in sorted(label_counts.index):\n",
    "    count = label_counts[label]\n",
    "    pct = 100 * count / total\n",
    "    print(f\"  Label {label} ({label_names[label]:10}): {count:4d} samples ({pct:5.1f}%)\")\n",
    "\n",
    "# Imbalance ratio\n",
    "max_count = label_counts.max()\n",
    "min_count = label_counts.min()\n",
    "imbalance_ratio = max_count / min_count\n",
    "\n",
    "print(f\"\\nImbalance Ratio (max/min): {imbalance_ratio:.2f}\")\n",
    "print(f\"Majority class: Label {label_counts.idxmax()} ({label_names[label_counts.idxmax()]})\")\n",
    "print(f\"Minority class: Label {label_counts.idxmin()} ({label_names[label_counts.idxmin()]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights for training\n",
    "labels = df['label'].values\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
    "class_weight_dict = {i+1: w for i, w in enumerate(class_weights)}\n",
    "\n",
    "print(\"Recommended Class Weights (balanced):\")\n",
    "print(\"=\"*50)\n",
    "for label in sorted(class_weight_dict.keys()):\n",
    "    weight = class_weight_dict[label]\n",
    "    print(f\"  Label {label} ({label_names[label]:10}): {weight:.4f}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Class distribution\n",
    "colors = sns.color_palette('RdYlGn', 5)\n",
    "axes[0].bar(label_counts.index, label_counts.values, color=colors)\n",
    "axes[0].set_xlabel('Understandability Label')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Class Distribution')\n",
    "axes[0].set_xticks([1, 2, 3, 4, 5])\n",
    "axes[0].axhline(y=total/5, color='red', linestyle='--', alpha=0.7, label='Balanced')\n",
    "axes[0].legend()\n",
    "\n",
    "# Class weights\n",
    "weight_values = [class_weight_dict[i] for i in range(1, 6)]\n",
    "axes[1].bar(range(1, 6), weight_values, color=colors)\n",
    "axes[1].set_xlabel('Label')\n",
    "axes[1].set_ylabel('Weight')\n",
    "axes[1].set_title('Computed Class Weights')\n",
    "axes[1].set_xticks([1, 2, 3, 4, 5])\n",
    "axes[1].axhline(y=1.0, color='red', linestyle='--', alpha=0.7, label='Baseline')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../notebook/class_imbalance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Annotator Bias Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean label per source folder (annotator tendency)\n",
    "mean_label_by_source = df.groupby('source_folder')['label'].agg(['mean', 'std', 'count']).sort_values('mean')\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "bars = plt.bar(range(len(mean_label_by_source)), mean_label_by_source['mean'])\n",
    "plt.errorbar(range(len(mean_label_by_source)), mean_label_by_source['mean'], \n",
    "             yerr=mean_label_by_source['std'], fmt='none', color='black', capsize=3)\n",
    "plt.xticks(range(len(mean_label_by_source)), mean_label_by_source.index, rotation=45, ha='right')\n",
    "plt.xlabel('Source Folder (Annotator)')\n",
    "plt.ylabel('Mean Label')\n",
    "plt.title('Mean Understandability Label by Data Source')\n",
    "plt.axhline(y=df['label'].mean(), color='red', linestyle='--', label=f'Overall Mean: {df[\"label\"].mean():.2f}')\n",
    "plt.legend()\n",
    "plt.ylim(1, 5)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../notebook/annotator_bias.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nOverall mean label: {df['label'].mean():.3f}\")\n",
    "print(f\"Std of mean labels across sources: {mean_label_by_source['mean'].std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-square test for independence between source and label\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "contingency_table = pd.crosstab(df['source_folder'], df['label'])\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "print(f\"Chi-square test for source-label independence:\")\n",
    "print(f\"  Chi-square statistic: {chi2:.2f}\")\n",
    "print(f\"  Degrees of freedom: {dof}\")\n",
    "print(f\"  P-value: {p_value:.2e}\")\n",
    "print(f\"\\nInterpretation: {'Significant dependency' if p_value < 0.05 else 'No significant dependency'} between source and label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Length vs Label Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between text length and label\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "pearson_corr, pearson_p = pearsonr(df['text_length'], df['label'])\n",
    "spearman_corr, spearman_p = spearmanr(df['text_length'], df['label'])\n",
    "\n",
    "print(\"Correlation between text length and label:\")\n",
    "print(f\"  Pearson:  r = {pearson_corr:.4f}, p = {pearson_p:.4e}\")\n",
    "print(f\"  Spearman: ρ = {spearman_corr:.4f}, p = {spearman_p:.4e}\")\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['text_length'], df['label'] + np.random.normal(0, 0.1, len(df)), alpha=0.3)\n",
    "plt.xlabel('Text Length (characters)')\n",
    "plt.ylabel('Understandability Label')\n",
    "plt.title(f'Text Length vs Label (Spearman ρ = {spearman_corr:.3f})')\n",
    "plt.yticks([1, 2, 3, 4, 5])\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(df['text_length'], df['label'], 1)\n",
    "p = np.poly1d(z)\n",
    "x_range = np.linspace(df['text_length'].min(), df['text_length'].max(), 100)\n",
    "plt.plot(x_range, p(x_range), 'r-', linewidth=2, label='Linear trend')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../notebook/length_vs_label.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot of text length by label\n",
    "plt.figure(figsize=(10, 6))\n",
    "df.boxplot(column='text_length', by='label')\n",
    "plt.xlabel('Understandability Label')\n",
    "plt.ylabel('Text Length (characters)')\n",
    "plt.title('Text Length Distribution by Label')\n",
    "plt.suptitle('')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../notebook/length_boxplot_by_label.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Mean length per label\n",
    "print(\"\\nMean text length by label:\")\n",
    "for label in sorted(df['label'].unique()):\n",
    "    mean_len = df[df['label'] == label]['text_length'].mean()\n",
    "    median_len = df[df['label'] == label]['text_length'].median()\n",
    "    print(f\"  Label {label}: mean={mean_len:.0f}, median={median_len:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ordinal Label Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion patterns - for ordinal data, errors between adjacent classes are \"better\"\n",
    "# Let's analyze the ordinal nature of labels\n",
    "\n",
    "# Adjacent label pairs\n",
    "print(\"Adjacent class boundaries:\")\n",
    "for i in range(1, 5):\n",
    "    count_lower = label_counts[i]\n",
    "    count_upper = label_counts[i+1]\n",
    "    boundary_samples = count_lower + count_upper\n",
    "    print(f\"  {i} ↔ {i+1}: {boundary_samples} samples ({100*boundary_samples/total:.1f}%)\")\n",
    "\n",
    "# This helps understand where ordinal loss might be most beneficial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative distribution - useful for ordinal regression perspective\n",
    "cumulative_counts = label_counts.sort_index().cumsum()\n",
    "cumulative_pct = 100 * cumulative_counts / total\n",
    "\n",
    "print(\"\\nCumulative Distribution:\")\n",
    "print(\"=\"*50)\n",
    "for label in sorted(label_counts.index):\n",
    "    print(f\"  P(label ≤ {label}): {cumulative_pct[label]:.1f}%\")\n",
    "\n",
    "# Visualize cumulative distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(cumulative_counts.index, cumulative_pct.values, alpha=0.7, color='steelblue')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Cumulative Percentage')\n",
    "plt.title('Cumulative Label Distribution')\n",
    "plt.xticks([1, 2, 3, 4, 5])\n",
    "plt.ylim(0, 105)\n",
    "\n",
    "# Add horizontal lines at key percentiles\n",
    "for pct in [25, 50, 75]:\n",
    "    plt.axhline(y=pct, color='red', linestyle='--', alpha=0.5)\n",
    "    plt.text(5.3, pct, f'{pct}%', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../notebook/cumulative_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"LABEL ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n1. CLASS IMBALANCE:\")\n",
    "print(f\"   - Imbalance ratio: {imbalance_ratio:.2f}x\")\n",
    "print(f\"   - Minority class (Label 1): {label_counts[1]} samples ({100*label_counts[1]/total:.1f}%)\")\n",
    "print(f\"   - Majority classes (Labels 4,5): {label_counts[4]+label_counts[5]} samples ({100*(label_counts[4]+label_counts[5])/total:.1f}%)\")\n",
    "\n",
    "print(f\"\\n2. ANNOTATOR VARIATION:\")\n",
    "print(f\"   - Mean label varies from {mean_label_by_source['mean'].min():.2f} to {mean_label_by_source['mean'].max():.2f} across sources\")\n",
    "print(f\"   - Chi-square p-value: {p_value:.2e} ({'Significant' if p_value < 0.05 else 'Not significant'} source effect)\")\n",
    "\n",
    "print(f\"\\n3. TEXT LENGTH CORRELATION:\")\n",
    "print(f\"   - Spearman correlation: {spearman_corr:.4f}\")\n",
    "print(f\"   - {'Negative' if spearman_corr < 0 else 'Positive'} correlation: longer texts tend to be rated as {'harder' if spearman_corr < 0 else 'easier'}\")\n",
    "\n",
    "print(f\"\\n4. RECOMMENDATIONS:\")\n",
    "print(f\"   - Use class weights during training to handle imbalance\")\n",
    "print(f\"   - Ordinal cross-entropy loss is appropriate given the ordinal nature of labels\")\n",
    "print(f\"   - Consider text length as a potential feature or confound\")\n",
    "\n",
    "print(f\"\\n5. CLASS WEIGHTS FOR TRAINING:\")\n",
    "for label in sorted(class_weight_dict.keys()):\n",
    "    print(f\"   Label {label}: {class_weight_dict[label]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save class weights for use in training\n",
    "import json\n",
    "\n",
    "weights_config = {\n",
    "    'class_weights': class_weight_dict,\n",
    "    'imbalance_ratio': imbalance_ratio,\n",
    "    'label_counts': {int(k): int(v) for k, v in label_counts.items()},\n",
    "    'mean_label': float(df['label'].mean()),\n",
    "    'text_length_correlation': float(spearman_corr)\n",
    "}\n",
    "\n",
    "with open('../data/processed/label_analysis.json', 'w') as f:\n",
    "    json.dump(weights_config, f, indent=2)\n",
    "\n",
    "print(\"Label analysis saved to data/processed/label_analysis.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
